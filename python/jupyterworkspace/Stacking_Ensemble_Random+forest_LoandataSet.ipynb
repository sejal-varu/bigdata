{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression # Logistic Regression module import\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0         0.0             360.0   \n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "3             2583             2358.0       120.0             360.0   \n",
       "4             6000                0.0       141.0             360.0   \n",
       "\n",
       "   Credit_History  Loan_Status  \n",
       "0             1.0            1  \n",
       "1             1.0            0  \n",
       "2             1.0            1  \n",
       "3             1.0            1  \n",
       "4             1.0            1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/Ramesh/Documents/DataScience/python/jupyterworkspace/ML/loan_prediction.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(552, 5) (552,)\n",
      "(62, 5) (62,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=9)\n",
    "print X_train.shape, y_train.shape\n",
    "print X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(496, 5) (496,)\n",
      "(56, 5) (56,)\n"
     ]
    }
   ],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_train, y_train, test_size=0.1, random_state=9)\n",
    "print X_train1.shape, y_train1.shape\n",
    "print X_test1.shape, y_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.33018868,  0.33018868,  0.7890625 ,  0.7890625 ,  0.7890625 ,\n",
       "        0.7890625 ,  0.7890625 ,  0.7890625 ,  0.7890625 ,  0.33018868,\n",
       "        0.33018868,  0.7890625 ,  0.7890625 ,  0.7890625 ,  0.7890625 ,\n",
       "        0.7890625 ,  0.7890625 ,  0.7890625 ,  0.7890625 ,  0.7890625 ,\n",
       "        0.7890625 ,  0.7890625 ,  0.33018868,  0.7890625 ,  0.7890625 ,\n",
       "        0.33018868,  0.7890625 ,  0.7890625 ,  0.33018868,  0.7890625 ,\n",
       "        0.7890625 ,  0.7890625 ,  0.7890625 ,  0.7890625 ,  0.33018868,\n",
       "        0.7890625 ,  0.7890625 ,  0.7890625 ,  0.7890625 ,  0.33018868,\n",
       "        0.33018868,  0.7890625 ,  0.33018868,  0.7890625 ,  0.33018868,\n",
       "        0.7890625 ,  0.33018868,  0.7890625 ,  0.7890625 ,  0.33018868,\n",
       "        0.7890625 ,  0.7890625 ,  0.7890625 ,  0.7890625 ,  0.33018868,\n",
       "        0.7890625 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model-1\n",
    "clf_gini = DecisionTreeClassifier(criterion='gini', max_depth=2)\n",
    "clf_gini.fit(X_train1,y_train1)\n",
    "\n",
    "y_prediction_gini = clf_gini.predict_proba(X_test1)[:,1]\n",
    "y_prediction_gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.35849057,  0.35849057,  0.92682927,  0.67857143,  1.        ,\n",
       "        0.88888889,  1.        ,  1.        ,  0.67857143,  0.35849057,\n",
       "        0.35849057,  0.92682927,  1.        ,  1.        ,  0.45454545,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  0.95238095,\n",
       "        1.        ,  0.6       ,  1.        ,  1.        ,  0.92682927,\n",
       "        0.35849057,  0.76744186,  0.        ,  0.14285714,  0.6       ,\n",
       "        0.88888889,  0.4       ,  1.        ,  1.        ,  1.        ,\n",
       "        0.67857143,  0.95238095,  0.6       ,  0.        ,  0.35849057,\n",
       "        1.        ,  1.        ,  0.14285714,  0.76744186,  0.        ,\n",
       "        1.        ,  0.14285714,  0.76744186,  1.        ,  0.35849057,\n",
       "        1.        ,  0.5       ,  0.76744186,  1.        ,  1.        ,  0.        ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model-2\n",
    "clf_entropy = DecisionTreeClassifier(criterion='entropy', max_depth=9)\n",
    "clf_entropy.fit(X_train1,y_train1)\n",
    "\n",
    "y_prediction_entropy = clf_entropy.predict_proba(X_test1)[:,1]\n",
    "y_prediction_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.35791714,  0.38540814,  0.78143552,  0.78587786,  0.76906856,\n",
       "        0.78721955,  0.77422243,  0.78066258,  0.75970475,  0.37713259,\n",
       "        0.3667054 ,  0.75147311,  0.75855411,  0.78453696,  0.77397198,\n",
       "        0.76071281,  0.77832401,  0.7826372 ,  0.77012267,  0.77714084,\n",
       "        0.77241844,  0.75246357,  0.36021222,  0.7790081 ,  0.78714171,\n",
       "        0.38452508,  0.79709963,  0.77430136,  0.36536413,  0.76733824,\n",
       "        0.78476001,  0.78469388,  0.77324406,  0.76196803,  0.37718705,\n",
       "        0.78713743,  0.74698963,  0.81711879,  0.7853364 ,  0.38086337,\n",
       "        0.37930286,  0.78248697,  0.38457594,  0.79154687,  0.41798915,\n",
       "        0.77265238,  0.37578353,  0.80831882,  0.81172227,  0.38676241,\n",
       "        0.78600241,  0.77946433,  0.82249444,  0.78943627,  0.35014813,\n",
       "        0.77131125])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model-3\n",
    "clf_LR = LogisticRegression()\n",
    "clf_LR.fit(X_train1, y_train1)\n",
    "\n",
    "y_predict_LR = clf_LR.predict_proba(X_test1)[:,1]\n",
    "y_predict_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.35066197,  0.37869116,  0.78328517,  0.7885229 ,  0.76917539,\n",
       "        0.7887654 ,  0.77526593,  0.78389274,  0.76027282,  0.37145449,\n",
       "        0.35969194,  0.75082252,  0.76232086,  0.80090642,  0.77353459,\n",
       "        0.75928866,  0.78098612,  0.78499941,  0.77116399,  0.78039452,\n",
       "        0.77500154,  0.75399112,  0.35482016,  0.78168165,  0.78929697,\n",
       "        0.401868  ,  0.79716036,  0.77539353,  0.35973344,  0.7689074 ,\n",
       "        0.78591821,  0.78795473,  0.77356051,  0.76234003,  0.3950947 ,\n",
       "        0.78964057,  0.74781139,  0.8476163 ,  0.80358572,  0.37129434,\n",
       "        0.37416119,  0.78415988,  0.37937439,  0.79207393,  0.46203301,\n",
       "        0.77216173,  0.3701487 ,  0.80522778,  0.81282798,  0.38093619,\n",
       "        0.78933067,  0.78193365,  0.81947631,  0.79217329,  0.3296444 ,\n",
       "        0.77266956])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model-4\n",
    "clf_LR_L1 = LogisticRegression(penalty=\"l1\")\n",
    "clf_LR_L1.fit(X_train1, y_train1)\n",
    "\n",
    "y_predict_LR_L1 = clf_LR_L1.predict_proba(X_test1)[:,1]\n",
    "y_predict_LR_L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.34956564,  0.37743508,  0.78345399,  0.78852875,  0.76978722,\n",
       "        0.78907735,  0.77573557,  0.7837463 ,  0.76078165,  0.36997605,\n",
       "        0.35855756,  0.75137879,  0.76196182,  0.7988165 ,  0.77437905,\n",
       "        0.76037896,  0.78100955,  0.78508822,  0.77160288,  0.78019388,\n",
       "        0.77506596,  0.75424886,  0.35323384,  0.78169367,  0.78942986,\n",
       "        0.3964801 ,  0.79787701,  0.7758209 ,  0.35821583,  0.76920306,\n",
       "        0.78627738,  0.78780371,  0.7741305 ,  0.76293637,  0.38952122,\n",
       "        0.78968911,  0.74797468,  0.84319397,  0.80097691,  0.37084503,\n",
       "        0.37248621,  0.78446694,  0.37774469,  0.7926313 ,  0.45201256,\n",
       "        0.77304562,  0.36857388,  0.8067754 ,  0.81336549,  0.37947151,\n",
       "        0.78917203,  0.78198363,  0.82108441,  0.79218017,  0.33063134,\n",
       "        0.77302103])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model-4\n",
    "clf_LR_L2 = LogisticRegression(penalty=\"l1\", random_state=5)\n",
    "clf_LR_L2.fit(X_train1, y_train1)\n",
    "\n",
    "y_predict_LR_L2 = clf_LR_L2.predict_proba(X_test1)[:,1]\n",
    "y_predict_LR_L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>p5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.330189</td>\n",
       "      <td>0.358491</td>\n",
       "      <td>0.357917</td>\n",
       "      <td>0.350662</td>\n",
       "      <td>0.349566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.330189</td>\n",
       "      <td>0.358491</td>\n",
       "      <td>0.385408</td>\n",
       "      <td>0.378691</td>\n",
       "      <td>0.377435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.781436</td>\n",
       "      <td>0.783285</td>\n",
       "      <td>0.783454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.785878</td>\n",
       "      <td>0.788523</td>\n",
       "      <td>0.788529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769069</td>\n",
       "      <td>0.769175</td>\n",
       "      <td>0.769787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.787220</td>\n",
       "      <td>0.788765</td>\n",
       "      <td>0.789077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.774222</td>\n",
       "      <td>0.775266</td>\n",
       "      <td>0.775736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.780663</td>\n",
       "      <td>0.783893</td>\n",
       "      <td>0.783746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.759705</td>\n",
       "      <td>0.760273</td>\n",
       "      <td>0.760782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.330189</td>\n",
       "      <td>0.358491</td>\n",
       "      <td>0.377133</td>\n",
       "      <td>0.371454</td>\n",
       "      <td>0.369976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.330189</td>\n",
       "      <td>0.358491</td>\n",
       "      <td>0.366705</td>\n",
       "      <td>0.359692</td>\n",
       "      <td>0.358558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.751473</td>\n",
       "      <td>0.750823</td>\n",
       "      <td>0.751379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.758554</td>\n",
       "      <td>0.762321</td>\n",
       "      <td>0.761962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.784537</td>\n",
       "      <td>0.800906</td>\n",
       "      <td>0.798817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.773972</td>\n",
       "      <td>0.773535</td>\n",
       "      <td>0.774379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.760713</td>\n",
       "      <td>0.759289</td>\n",
       "      <td>0.760379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.778324</td>\n",
       "      <td>0.780986</td>\n",
       "      <td>0.781010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.782637</td>\n",
       "      <td>0.784999</td>\n",
       "      <td>0.785088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.770123</td>\n",
       "      <td>0.771164</td>\n",
       "      <td>0.771603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.777141</td>\n",
       "      <td>0.780395</td>\n",
       "      <td>0.780194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.772418</td>\n",
       "      <td>0.775002</td>\n",
       "      <td>0.775066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.752464</td>\n",
       "      <td>0.753991</td>\n",
       "      <td>0.754249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.330189</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.360212</td>\n",
       "      <td>0.354820</td>\n",
       "      <td>0.353234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.779008</td>\n",
       "      <td>0.781682</td>\n",
       "      <td>0.781694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.787142</td>\n",
       "      <td>0.789297</td>\n",
       "      <td>0.789430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.330189</td>\n",
       "      <td>0.358491</td>\n",
       "      <td>0.384525</td>\n",
       "      <td>0.401868</td>\n",
       "      <td>0.396480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.797100</td>\n",
       "      <td>0.797160</td>\n",
       "      <td>0.797877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.774301</td>\n",
       "      <td>0.775394</td>\n",
       "      <td>0.775821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.330189</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.365364</td>\n",
       "      <td>0.359733</td>\n",
       "      <td>0.358216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.767338</td>\n",
       "      <td>0.768907</td>\n",
       "      <td>0.769203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.784760</td>\n",
       "      <td>0.785918</td>\n",
       "      <td>0.786277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.784694</td>\n",
       "      <td>0.787955</td>\n",
       "      <td>0.787804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773244</td>\n",
       "      <td>0.773561</td>\n",
       "      <td>0.774130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.761968</td>\n",
       "      <td>0.762340</td>\n",
       "      <td>0.762936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.330189</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.377187</td>\n",
       "      <td>0.395095</td>\n",
       "      <td>0.389521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.787137</td>\n",
       "      <td>0.789641</td>\n",
       "      <td>0.789689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.746990</td>\n",
       "      <td>0.747811</td>\n",
       "      <td>0.747975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.817119</td>\n",
       "      <td>0.847616</td>\n",
       "      <td>0.843194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.785336</td>\n",
       "      <td>0.803586</td>\n",
       "      <td>0.800977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.330189</td>\n",
       "      <td>0.358491</td>\n",
       "      <td>0.380863</td>\n",
       "      <td>0.371294</td>\n",
       "      <td>0.370845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.330189</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.379303</td>\n",
       "      <td>0.374161</td>\n",
       "      <td>0.372486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.782487</td>\n",
       "      <td>0.784160</td>\n",
       "      <td>0.784467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.330189</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.384576</td>\n",
       "      <td>0.379374</td>\n",
       "      <td>0.377745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.791547</td>\n",
       "      <td>0.792074</td>\n",
       "      <td>0.792631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.330189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.417989</td>\n",
       "      <td>0.462033</td>\n",
       "      <td>0.452013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.772652</td>\n",
       "      <td>0.772162</td>\n",
       "      <td>0.773046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.330189</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.375784</td>\n",
       "      <td>0.370149</td>\n",
       "      <td>0.368574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.808319</td>\n",
       "      <td>0.805228</td>\n",
       "      <td>0.806775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.811722</td>\n",
       "      <td>0.812828</td>\n",
       "      <td>0.813365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.330189</td>\n",
       "      <td>0.358491</td>\n",
       "      <td>0.386762</td>\n",
       "      <td>0.380936</td>\n",
       "      <td>0.379472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.786002</td>\n",
       "      <td>0.789331</td>\n",
       "      <td>0.789172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.779464</td>\n",
       "      <td>0.781934</td>\n",
       "      <td>0.781984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.822494</td>\n",
       "      <td>0.819476</td>\n",
       "      <td>0.821084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.789436</td>\n",
       "      <td>0.792173</td>\n",
       "      <td>0.792180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.330189</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.350148</td>\n",
       "      <td>0.329644</td>\n",
       "      <td>0.330631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.771311</td>\n",
       "      <td>0.772670</td>\n",
       "      <td>0.773021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          p1        p2        p3        p4        p5\n",
       "0   0.330189  0.358491  0.357917  0.350662  0.349566\n",
       "1   0.330189  0.358491  0.385408  0.378691  0.377435\n",
       "2   0.789062  0.926829  0.781436  0.783285  0.783454\n",
       "3   0.789062  0.678571  0.785878  0.788523  0.788529\n",
       "4   0.789062  1.000000  0.769069  0.769175  0.769787\n",
       "5   0.789062  0.888889  0.787220  0.788765  0.789077\n",
       "6   0.789062  1.000000  0.774222  0.775266  0.775736\n",
       "7   0.789062  1.000000  0.780663  0.783893  0.783746\n",
       "8   0.789062  0.678571  0.759705  0.760273  0.760782\n",
       "9   0.330189  0.358491  0.377133  0.371454  0.369976\n",
       "10  0.330189  0.358491  0.366705  0.359692  0.358558\n",
       "11  0.789062  0.926829  0.751473  0.750823  0.751379\n",
       "12  0.789062  1.000000  0.758554  0.762321  0.761962\n",
       "13  0.789062  1.000000  0.784537  0.800906  0.798817\n",
       "14  0.789062  0.454545  0.773972  0.773535  0.774379\n",
       "15  0.789062  1.000000  0.760713  0.759289  0.760379\n",
       "16  0.789062  1.000000  0.778324  0.780986  0.781010\n",
       "17  0.789062  1.000000  0.782637  0.784999  0.785088\n",
       "18  0.789062  1.000000  0.770123  0.771164  0.771603\n",
       "19  0.789062  0.952381  0.777141  0.780395  0.780194\n",
       "20  0.789062  1.000000  0.772418  0.775002  0.775066\n",
       "21  0.789062  0.600000  0.752464  0.753991  0.754249\n",
       "22  0.330189  1.000000  0.360212  0.354820  0.353234\n",
       "23  0.789062  1.000000  0.779008  0.781682  0.781694\n",
       "24  0.789062  0.926829  0.787142  0.789297  0.789430\n",
       "25  0.330189  0.358491  0.384525  0.401868  0.396480\n",
       "26  0.789062  0.767442  0.797100  0.797160  0.797877\n",
       "27  0.789062  0.000000  0.774301  0.775394  0.775821\n",
       "28  0.330189  0.142857  0.365364  0.359733  0.358216\n",
       "29  0.789062  0.600000  0.767338  0.768907  0.769203\n",
       "30  0.789062  0.888889  0.784760  0.785918  0.786277\n",
       "31  0.789062  0.400000  0.784694  0.787955  0.787804\n",
       "32  0.789062  1.000000  0.773244  0.773561  0.774130\n",
       "33  0.789062  1.000000  0.761968  0.762340  0.762936\n",
       "34  0.330189  1.000000  0.377187  0.395095  0.389521\n",
       "35  0.789062  0.678571  0.787137  0.789641  0.789689\n",
       "36  0.789062  0.952381  0.746990  0.747811  0.747975\n",
       "37  0.789062  0.600000  0.817119  0.847616  0.843194\n",
       "38  0.789062  0.000000  0.785336  0.803586  0.800977\n",
       "39  0.330189  0.358491  0.380863  0.371294  0.370845\n",
       "40  0.330189  1.000000  0.379303  0.374161  0.372486\n",
       "41  0.789062  1.000000  0.782487  0.784160  0.784467\n",
       "42  0.330189  0.142857  0.384576  0.379374  0.377745\n",
       "43  0.789062  0.767442  0.791547  0.792074  0.792631\n",
       "44  0.330189  0.000000  0.417989  0.462033  0.452013\n",
       "45  0.789062  1.000000  0.772652  0.772162  0.773046\n",
       "46  0.330189  0.142857  0.375784  0.370149  0.368574\n",
       "47  0.789062  0.767442  0.808319  0.805228  0.806775\n",
       "48  0.789062  1.000000  0.811722  0.812828  0.813365\n",
       "49  0.330189  0.358491  0.386762  0.380936  0.379472\n",
       "50  0.789062  1.000000  0.786002  0.789331  0.789172\n",
       "51  0.789062  0.500000  0.779464  0.781934  0.781984\n",
       "52  0.789062  0.767442  0.822494  0.819476  0.821084\n",
       "53  0.789062  1.000000  0.789436  0.792173  0.792180\n",
       "54  0.330189  1.000000  0.350148  0.329644  0.330631\n",
       "55  0.789062  0.000000  0.771311  0.772670  0.773021"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_probs = pd.DataFrame(list(zip(y_prediction_gini, y_prediction_entropy, y_predict_LR, y_predict_LR_L1, y_predict_LR_L2)), columns=['p1','p2','p3','p4','p5'])\n",
    "all_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators= 1000, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.629  0.573  0.964  0.964  1.     1.     1.     1.     1.     0.629\n",
      "  0.629  0.964  0.73   1.     1.     1.     1.     1.     1.     0.964  1.\n",
      "  1.     0.629  1.     0.964  0.629  1.     1.     0.629  1.     0.964\n",
      "  0.964  1.     1.     0.629  0.964  0.964  0.526  0.964  0.629  0.573  1.\n",
      "  0.573  0.964  0.453  1.     0.573  0.964  0.964  0.573  0.964  1.     0.964\n",
      "  0.964  0.629  1.   ]\n"
     ]
    }
   ],
   "source": [
    "rf.fit(all_probs, y_test1)\n",
    "meta_prob = rf.predict(X_test1)\n",
    "print meta_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83495934959349594"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc = metrics.roc_auc_score(y_test1, meta_prob)\n",
    "auc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
